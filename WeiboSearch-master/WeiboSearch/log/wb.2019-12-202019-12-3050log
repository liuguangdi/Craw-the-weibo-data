2020-01-29 15:29:18 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: WeiboSearch)
2020-01-29 15:29:18 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.0 (v3.7.0:1bf9cc5093, Jun 26 2018, 23:26:24) - [Clang 6.0 (clang-600.0.57)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Darwin-19.2.0-x86_64-i386-64bit
2020-01-29 15:29:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'WeiboSearch', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': '\\log\\wb.2019-12-202019-12-3050log', 'NEWSPIDER_MODULE': 'WeiboSearch.spiders', 'RETRY_HTTP_CODES': [401, 403, 408, 414, 500, 502, 503, 504], 'SPIDER_MODULES': ['WeiboSearch.spiders'], 'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.24 (KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24'}
2020-01-29 15:29:18 [scrapy.extensions.telnet] INFO: Telnet Password: d513a2f3a44e3545
2020-01-29 15:29:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-01-29 15:29:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'WeiboSearch.middlewares.CookiesMiddleware',
 'WeiboSearch.middlewares.ProxyMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-01-29 15:29:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-01-29 15:29:19 [scrapy.middleware] INFO: Enabled item pipelines:
['WeiboSearch.pipelines.TimePipeline',
 'WeiboSearch.pipelines.WeiboSpiderPipeline',
 'WeiboSearch.pipelines.MongoPipeline']
2020-01-29 15:29:19 [scrapy.core.engine] INFO: Spider opened
2020-01-29 15:29:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-01-29 15:29:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): 127.0.0.1:5000
2020-01-29 15:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191220&endtime=20191220&sort=hot> (referer: None)
2020-01-29 15:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191222&endtime=20191222&sort=hot> (referer: None)
2020-01-29 15:29:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191221&endtime=20191221&sort=hot> (referer: None)
2020-01-29 15:29:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191223&endtime=20191223&sort=hot> (referer: None)
2020-01-29 15:29:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191224&endtime=20191224&sort=hot> (referer: None)
2020-01-29 15:29:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191224&endtime=20191224&sort=hot>
{'comment_num': 217,
 'content': '伍只蜜桃:#郑在玹HIGHCUT开年双封#🍑#郑在玹0214生日快乐#🍑ʜᴀᴘᴘʏʙɪʀᴛʜᴅᴀʏᴛᴏᴊᴀᴇʜʏᴜɴ🍑郑在玹24岁生日七城联合线下应援【重庆武汉深圳合肥天津长沙广州】【由于新型肺炎疫情形势严峻综合考虑后此次应援延期具体时间另行通知】“我想是不期的而遇在二月的春风里遇见了你我想是春天的旨意风把你吹到这里”转发带话题#郑在玹0214生日快乐#+@2位好友抽十位送基础set（邮费自理）🌸详情领取条件请点开公告🌸仔细阅读🌸📍地址：公告图为大致地址⚠️深圳【以下为正确地址】⚠️：深圳市南山区凯德公园1号B栋2单元一楼X-lifecafe📍详细地址移步各地区负责人主页：重庆：@水水文呀武汉：@cherryontop-深圳：@一罐lychee炮筒酱合肥：@伍只蜜桃天津：@秋日不限量长沙：@Jessieason广州：@橘味桃茶🍨店内布置详情请点开公告图🎀感谢以下给小玹绝美授权图的站姐和粉丝：（排名不分先后）@motorway0214@MA1GG_@Hy_un214@eyeronicmuch@misslove_P@jh_theory@PeachMong_o@-Nnnan@vitamintJ@MUSEFILM@郑Jing怡_Gr@SongLi宋宋er🎀感谢以下姐妹对此次应援加码：@桃桃不想逃@灿灿N啊C啊T啊@桃汁果粒@-hyunhyun-🎀感谢姐妹帮忙设计公告图：@NoctiflorouSakura💌感谢以下姐妹对这次七城联合的支持：@香甜猪猪包@白蝴蝶记事簿@情比金坚的追星姐妹@养乐多咘多@秋山岚@Kiss一下吧@思抓贝瑞冰淇淋@红区一等舞客@Instantcrushonyou@一起晒太阳呀@H2O14@酸奶倒计时@桃汁果粒@梨与鲜橙@一粒紫菜_@追青的葵花籽@崔沢@智久1@梅花夹心饼干@春桵奈奈子@人型懒蛋蛋@不造叫啥啊TT@桃子烧酒呀@超级小绒⚠️：①中阶jz：限郑在玹相关周边/玹吧生日集资②高阶jz：限玹吧郑在玹生日集资③关于代领：详情领取条件见公告图📎：此次生日应援所有应援物不得二次转卖希望尊重劳动成果🍑期待与各位姐妹一起度过美好的情人节～🍑[组图共6张]',
 'crawled_at': '2020-01-29 15:29',
 'created_at': '2019-12-24 20:14:38',
 'id': '5644791784_ImhRd3CMn',
 'image_url': 'http://wx1.sinaimg.cn/wap180/006a0YcMly1ga82f5kegrj326r7nlu12.jpg',
 'like_num': 303,
 'repost_num': 358,
 'tool': '郑在玹超话',
 'user_id': '5644791784',
 'weibo_url': 'https://weibo.com/5644791784/ImhRd3CMn'}
2020-01-29 15:29:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191225&endtime=20191225&sort=hot> (referer: None)
2020-01-29 15:29:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191226&endtime=20191226&sort=hot> (referer: None)
2020-01-29 15:29:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191227&endtime=20191227&sort=hot> (referer: None)
2020-01-29 15:29:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191228&endtime=20191228&sort=hot> (referer: None)
2020-01-29 15:29:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://weibo.cn/search/mblog?hideSearchFrame=&keyword=%E6%AD%A6%E6%B1%89,%E8%82%BA%E7%82%8E&advancedfilter=1&starttime=20191229&endtime=20191229&sort=hot> (referer: None)
2020-01-29 15:29:32 [scrapy.core.engine] INFO: Closing spider (finished)
2020-01-29 15:29:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 8080,
 'downloader/request_count': 10,
 'downloader/request_method_count/GET': 10,
 'downloader/response_bytes': 39848,
 'downloader/response_count': 10,
 'downloader/response_status_count/200': 10,
 'elapsed_time_seconds': 12.542122,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 1, 29, 15, 29, 32, 132068),
 'item_scraped_count': 1,
 'log_count/DEBUG': 21,
 'log_count/INFO': 10,
 'memusage/max': 54603776,
 'memusage/startup': 54603776,
 'response_received_count': 10,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2020, 1, 29, 15, 29, 19, 589946)}
2020-01-29 15:29:32 [scrapy.core.engine] INFO: Spider closed (finished)
